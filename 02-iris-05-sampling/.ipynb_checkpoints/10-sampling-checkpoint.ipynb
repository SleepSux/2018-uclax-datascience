{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3ab850bf5a6987470d7a4274d06461a",
     "grade": false,
     "grade_id": "cell-789bd9c738365d25",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### What percentage of the entire dataset is the first sample of three points? How well does this sample do in representing the entire dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "32f08581ca285e6f1c3d7667375fed5b",
     "grade": true,
     "grade_id": "cell-cc1f92a3867713bc",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "2 percent. it pretty well. you can get a jist of what the data looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fdee1dd9ff034fdedf80af5b818a2051",
     "grade": false,
     "grade_id": "cell-fb1321a775c9f8e7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### What does this code do? \n",
    "\n",
    "Be as detailed as possible!\n",
    "\n",
    "    np.abs(iris_df.mean() - sample.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "50f488b7e8cb037a999be437a93cbd9f",
     "grade": true,
     "grade_id": "cell-cc09715f1753f7d0",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "It takes the absolute value of the diffrence between the whole data sets mean and the sample mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b22c04a0c9866760995790450495333",
     "grade": false,
     "grade_id": "cell-9853e24d6b22e6ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Why is it important to use the absolute value of the error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6f014a6b99459747ee53a97ec977eb4",
     "grade": true,
     "grade_id": "cell-ea2effaff04a5e0a",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "So you can inlude all errors even if they are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "27cfee6e4c02ff6f1efead4245097564",
     "grade": false,
     "grade_id": "cell-94990d6d7b03e580",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Why is it important to normalize the error by dividing by the standard deviation of the feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8306c6e6f62203a87974fc17384ae55",
     "grade": true,
     "grade_id": "cell-b4b921ad9ce0f2b2",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "So that their scales can match in weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03b3af6bd7221ce41738869b9c4ae09c",
     "grade": false,
     "grade_id": "cell-d3083e63c9669b1f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Why is it important to normalize the error by dividing by the standard deviation of the feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1065e777ced1d162be72816caaca2445",
     "grade": true,
     "grade_id": "cell-a1e64b00345e1435",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "So that their scales can match in weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2926a9f700533a8d0781f78e24d22564",
     "grade": false,
     "grade_id": "cell-1766b3cba5b4f291",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Prepare an Error Plot of all Four Features as a Function of `n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "717b4d05e39d02d52a7090f0a5af77fb",
     "grade": true,
     "grade_id": "cell-640bb26539430be2",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IRIS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-10141049e624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIRIS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miris_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIRIS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miris_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIRIS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIRIS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_error_by_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IRIS' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "IRIS = load_iris()\n",
    "plt.rc('figure', figsize=(20, 6))\n",
    "feat_names = IRIS.feature_names\n",
    "iris_df = pd.DataFrame(IRIS.data, columns=feat_names)\n",
    "\n",
    "iris_df['target'] = IRIS.target_names[IRIS.target]\n",
    "def feature_error_by_n(data, feature, n):\n",
    "    sample = data[feature].sample(n)\n",
    "    error = np.abs((data[feature].mean() - sample.mean())/data[feature].mean())\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "sepal_length_error_by_n = [feature_error_by_n(iris_df, 'sepal length (cm)', n) for n in range(1,151)]\n",
    "plt.plot(range(1,151), sepal_length_error_by_n, label='absolute error - sepal length mean by sample n')\n",
    "plt.legend()\n",
    "\n",
    "sepal_width_error_by_n = [feature_error_by_n(iris_df, 'sepal width (cm)', n) for n in range(1,151)]\n",
    "plt.plot(range(1,151), sepal_width_error_by_n, label='absolute error - sepal width mean by sample n')\n",
    "plt.legend()\n",
    "\n",
    "petal_width_error_by_n = [feature_error_by_n(iris_df, 'petal width (cm)', n) for n in range(1,151)]\n",
    "plt.plot(range(1,151), petal_width_error_by_n, label='absolute error - petal width mean by sample n')\n",
    "plt.legend()\n",
    "\n",
    "petal_length_error_by_n = [feature_error_by_n(iris_df, 'petal length (cm)', n) for n in range(1,151)]\n",
    "plt.plot(range(1,151), petal_length_error_by_n, label='absolute error - petal length mean by sample n')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2031f48e6f8b48d9ad27838c383dc1fd",
     "grade": false,
     "grade_id": "cell-271a692b8d0e363a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### What does the error we have been calculating represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e4e2998a6ac87cdfb5a3490b1f83e213",
     "grade": true,
     "grade_id": "cell-5bab83be85eaaff4",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "print('the error represents the probability of the sample size being wrong to how many samples you took from the actual data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = IRIS.feature_names\n",
    "iris_df = pd.DataFrame(IRIS.data, columns=feat_names)\n",
    "\n",
    "iris_df['target'] = IRIS.target_names[IRIS.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Distributions of the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.melt()`\n",
    "\n",
    "We can use `pandas.melt` to help with this visualization. Melt converts wide form data to long form data. So that\n",
    "\n",
    "    +---+---+---+\n",
    "    | A | B | C |\n",
    "    +===+===+===+\n",
    "    | 1 | 2 | 3 |\n",
    "    | 3 | 4 | 5 |\n",
    "    +---+---+---+\n",
    "    \n",
    "becomes\n",
    "\n",
    "    +-----+-----+\n",
    "    | var | val |\n",
    "    +=====+=====+\n",
    "    |  A  |  1  |\n",
    "    |  A  |  3  |\n",
    "    |  B  |  2  |\n",
    "    |  B  |  4  |\n",
    "    |  C  |  3  |\n",
    "    |  C  |  5  |\n",
    "    +-----+-----+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, is a sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = iris_df.sample(5)\n",
    "samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_melt = pd.melt(samp.select_dtypes([float]))\n",
    "samp_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the exact format expected of the box plot in Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_melt = pd.melt(iris_df.select_dtypes([float]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,4))\n",
    "sns.boxplot(x='variable', y='value', data=iris_melt)\n",
    "plt.ylim(-1,9)\n",
    "\n",
    "_, ax = plt.subplots(1,4, figsize=(20,4))\n",
    "iris_numerical_df = iris_df.select_dtypes([float])\n",
    "\n",
    "for i, feat in enumerate(iris_numerical_df.columns):\n",
    "    sns.distplot(iris_numerical_df[feat], ax=ax[i])\n",
    "    #ax[i].set_xlim(-1,9)\n",
    "    ax[i].axvline(iris_numerical_df[feat].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the Dataset\n",
    "\n",
    "In this notebook, we begin to explore the iris dataset by sampling. First, let's sample three random points and examine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = iris_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Differences Using Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIsualized with a Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1_melt = pd.melt(sample_1.select_dtypes([float]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=sample_1_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized with a Swarmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.swarmplot(x='variable', y='value', data=sample_1_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.swarmplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized with a Stripplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.stripplot(x='variable', y='value', data=sample_1_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.stripplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized with a Violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.violinplot(x='variable', y='value', data=sample_1_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.violinplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sample_1 = np.abs(iris_df.mean() - sample_1.mean())\n",
    "error_sample_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sample_1_normalized = np.abs((iris_df.mean() - sample_1.mean())/iris_df.mean())\n",
    "error_sample_1_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Second Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = iris_df.sample(3)\n",
    "\n",
    "sample_2_melt = pd.melt(sample_2.select_dtypes([float]))\n",
    "iris_melt = pd.melt(iris_df.select_dtypes([float]))\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=sample_2_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sample_2_normalized = np.abs((iris_df.mean() - sample_2.mean())/iris_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(error_sample_1_normalized)\n",
    "display(error_sample_2_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about a larger sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = iris_df.sample(15)\n",
    "\n",
    "sample_3_melt = pd.melt(sample_3.select_dtypes([float]))\n",
    "iris_melt = pd.melt(iris_df.select_dtypes([float]))\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=sample_3_melt, ax=ax[0])\n",
    "ax[0].set_title('Sample')\n",
    "\n",
    "sns.boxplot(x='variable', y='value', data=iris_melt, ax=ax[1])\n",
    "ax[1].set_title('Full Data Set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sample_3_normalized = np.abs((iris_df.mean() - sample_3.mean())/iris_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(error_sample_1_normalized)\n",
    "display(error_sample_2_normalized)\n",
    "display(error_sample_3_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Error as a Function of Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be useful to begin to think about the error in the mean as a function of sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_error_by_n(data, feature, n):\n",
    "    sample = data[feature].sample(n)\n",
    "    error = np.abs((data[feature].mean() - sample.mean())/data[feature].mean())\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_error_by_n(iris_df, 'sepal length (cm)', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a list comprehension to generate errors for every possible value of `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length_error_by_n = [feature_error_by_n(iris_df, 'sepal length (cm)', n) for n in range(1,151)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,151), sepal_length_error_by_n, label='absolute error - sepal length mean by sample n')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
